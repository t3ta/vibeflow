import fs from 'fs/promises';
import path from 'path';
import { RefactorAgent } from './refactor-agent';
import { MetadataCache, FileMetadata, ProjectMetadata } from '../utils/metadata-cache';
import { DomainBoundary } from '../types/config';

/**
 * MetadataDrivenRefactorAgent - ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿é§†å‹•ã®åŠ¹ç‡çš„ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°
 * äº‹å‰é™çš„è§£æ â†’ æœ€é©åŒ–ã•ã‚ŒãŸLLMå‘¼ã³å‡ºã— â†’ å¤§å¹…ãªãƒˆãƒ¼ã‚¯ãƒ³ç¯€ç´„
 */
export class MetadataDrivenRefactorAgent extends RefactorAgent {
  private metadataCache: MetadataCache;
  private projectMetadata?: ProjectMetadata;

  constructor(projectRoot: string) {
    super(projectRoot);
    this.metadataCache = new MetadataCache(projectRoot);
  }

  /**
   * ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿é§†å‹•ã®ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å®Ÿè¡Œ
   */
  async executeMetadataDrivenRefactoring(
    projectPath: string, 
    boundaries: DomainBoundary[]
  ): Promise<MetadataDrivenResult> {
    console.log('ğŸš€ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿é§†å‹•ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°é–‹å§‹...');
    
    // Phase 1: äº‹å‰é™çš„è§£æã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    await this.preAnalyzeProject(projectPath, boundaries);
    
    // Phase 2: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãæœ€é©åŒ–ã•ã‚ŒãŸå‡¦ç†
    const result = await this.processWithMetadata(boundaries);
    
    console.log(`ğŸ’¡ å‡¦ç†åŠ¹ç‡æ€§: ${result.efficiency.processingTimeReduction}% æ™‚é–“çŸ­ç¸®`);
    console.log(`ğŸ’° ãƒˆãƒ¼ã‚¯ãƒ³åŠ¹ç‡: ${result.efficiency.tokenReduction}% ãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸›`);
    
    return result;
  }

  /**
   * Phase 1: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã®äº‹å‰åˆ†æ
   */
  private async preAnalyzeProject(projectPath: string, boundaries: DomainBoundary[]): Promise<void> {
    console.log('ğŸ“Š Phase 1: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆäº‹å‰åˆ†æ...');
    
    // å…¨ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã®åé›†
    const allFiles = this.collectAllRelevantFiles(projectPath, boundaries);
    
    // ä¸¦åˆ—é™çš„è§£æã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥
    this.projectMetadata = await this.metadataCache.analyzeAndCacheFiles(allFiles);
    
    console.log(`âœ… ${this.projectMetadata.files.length}ãƒ•ã‚¡ã‚¤ãƒ«ã®äº‹å‰åˆ†æå®Œäº†`);
    console.log(`ğŸ” ${this.projectMetadata.businessClusters.length}å€‹ã®ãƒ“ã‚¸ãƒã‚¹ã‚¯ãƒ©ã‚¹ã‚¿ãƒ¼ã‚’ç™ºè¦‹`);
    console.log(`ğŸ“ˆ ${this.projectMetadata.codePatterns.length}å€‹ã®ã‚³ãƒ¼ãƒ‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è­˜åˆ¥`);
  }

  /**
   * Phase 2: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ´»ç”¨ã—ãŸæœ€é©åŒ–å‡¦ç†
   */
  private async processWithMetadata(boundaries: DomainBoundary[]): Promise<MetadataDrivenResult> {
    console.log('âš¡ Phase 2: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿é§†å‹•å‡¦ç†...');
    
    if (!this.projectMetadata) {
      throw new Error('Project metadata not available. Run preAnalyzeProject first.');
    }

    const result: MetadataDrivenResult = {
      boundaries: [],
      efficiency: {
        totalFiles: this.projectMetadata.files.length,
        llmProcessedFiles: 0,
        templateGeneratedFiles: 0,
        staticAnalyzedFiles: 0,
        processingTimeReduction: 0,
        tokenReduction: 0
      }
    };

    for (const boundary of boundaries) {
      const boundaryResult = await this.processBoundaryWithMetadata(boundary);
      result.boundaries.push(boundaryResult);
      
      // åŠ¹ç‡æ€§ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®é›†è¨ˆ
      result.efficiency.llmProcessedFiles += boundaryResult.llmProcessed.length;
      result.efficiency.templateGeneratedFiles += boundaryResult.templateGenerated.length;
      result.efficiency.staticAnalyzedFiles += boundaryResult.staticAnalyzed.length;
    }

    // åŠ¹ç‡æ€§ã®è¨ˆç®—
    this.calculateEfficiencyMetrics(result);
    
    return result;
  }

  /**
   * å¢ƒç•Œã”ã¨ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿é§†å‹•å‡¦ç†
   */
  private async processBoundaryWithMetadata(boundary: DomainBoundary): Promise<BoundaryResult> {
    const boundaryFiles = this.getBoundaryFiles(boundary);
    const optimizedPlan = this.createOptimizedProcessingPlan(boundaryFiles);
    
    console.log(`ğŸ¯ ${boundary.name}: ${optimizedPlan.llm.length}LLM + ${optimizedPlan.template.length}ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ + ${optimizedPlan.static.length}é™çš„`);

    const result: BoundaryResult = {
      boundary: boundary.name,
      llmProcessed: [],
      templateGenerated: [],
      staticAnalyzed: [],
      optimizations: optimizedPlan.optimizations
    };

    // 1. LLMå‡¦ç†ãŒå¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆè¤‡é›‘ãªãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
    if (optimizedPlan.llm.length > 0) {
      result.llmProcessed = await this.processWithLLMOptimized(optimizedPlan.llm, boundary);
    }

    // 2. ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”Ÿæˆå¯èƒ½ãªãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ‘ã‚¿ãƒ¼ãƒ³åŒ–ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ï¼‰
    if (optimizedPlan.template.length > 0) {
      result.templateGenerated = await this.processWithTemplates(optimizedPlan.template, boundary);
    }

    // 3. é™çš„è§£æã®ã¿ã§ååˆ†ãªãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆè¨­å®šãƒ»å®šæ•°ï¼‰
    if (optimizedPlan.static.length > 0) {
      result.staticAnalyzed = await this.processWithStaticAnalysis(optimizedPlan.static, boundary);
    }

    return result;
  }

  /**
   * ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãæœ€é©åŒ–ã•ã‚ŒãŸå‡¦ç†è¨ˆç”»ã®ä½œæˆ
   */
  private createOptimizedProcessingPlan(files: FileMetadata[]): OptimizedProcessingPlan {
    const plan: OptimizedProcessingPlan = {
      llm: [],
      template: [],
      static: [],
      optimizations: []
    };

    for (const file of files) {
      const approach = file.llmHints.suggestedApproach;
      
      switch (approach) {
        case 'full_llm':
          plan.llm.push(file);
          break;
        case 'template':
          plan.template.push(file);
          plan.optimizations.push(`Template processing for ${path.basename(file.path)}`);
          break;
        case 'static_only':
          plan.static.push(file);
          plan.optimizations.push(`Static analysis only for ${path.basename(file.path)}`);
          break;
      }
    }

    // ãƒãƒƒãƒå‡¦ç†ã®æœ€é©åŒ–
    plan.optimizations.push(...this.optimizeBatchProcessing(plan.llm));
    
    return plan;
  }

  /**
   * LLMå‡¦ç†ã®æœ€é©åŒ–ï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå„ªå…ˆåº¦ã¨ãƒãƒƒãƒãƒ³ã‚°ï¼‰
   */
  private async processWithLLMOptimized(files: FileMetadata[], boundary: DomainBoundary): Promise<ProcessedFile[]> {
    // å„ªå…ˆåº¦é †ã«ã‚½ãƒ¼ãƒˆ
    const sortedFiles = files.sort((a, b) => b.llmHints.contextPriority - a.llmHints.contextPriority);
    
    // é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒãƒƒãƒä½œæˆ
    const batches = this.createSmartBatches(sortedFiles);
    
    const results: ProcessedFile[] = [];
    
    for (const batch of batches) {
      console.log(`ğŸ¤– LLMãƒãƒƒãƒå‡¦ç†: ${batch.map(f => path.basename(f.path)).join(', ')}`);
      
      // ãƒãƒƒãƒç”¨ã®æœ€é©åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”Ÿæˆ
      const optimizedPrompt = this.generateOptimizedBatchPrompt(batch, boundary);
      
      // LLMå‡¦ç†å®Ÿè¡Œ
      const batchResult = await this.executeLLMBatch(batch, optimizedPrompt, boundary);
      results.push(...batchResult);
    }
    
    return results;
  }

  /**
   * æœ€é©åŒ–ã•ã‚ŒãŸãƒãƒƒãƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ç”Ÿæˆ
   */
  private generateOptimizedBatchPrompt(batch: FileMetadata[], boundary: DomainBoundary): string {
    // ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰é‡è¦ãªæƒ…å ±ã‚’æŠ½å‡º
    const businessConcepts = [...new Set(batch.flatMap(f => f.businessContext.domainConcepts))];
    const commonPatterns = this.identifyCommonPatterns(batch);
    
    return `
Transform these ${batch.length} related files to the "${boundary.name}" bounded context:

Business Context:
- Domain concepts: ${businessConcepts.join(', ')}
- Common patterns: ${commonPatterns.join(', ')}

Files to transform:
${batch.map((file, index) => `
## File ${index + 1}: ${path.basename(file.path)}
Business concepts: ${file.businessContext.domainConcepts.join(', ')}
Complexity: ${file.technicalComplexity.complexityScore}/10
Key functions: ${file.structure.functions.slice(0, 3).map(f => f.name).join(', ')}

\`\`\`${file.language}
${this.getRelevantCodeSnippet(file)}
\`\`\`
`).join('\n')}

Generate cohesive ${boundary.name} module architecture for all files above.
`;
  }

  /**
   * ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãƒ™ãƒ¼ã‚¹å‡¦ç†
   */
  private async processWithTemplates(files: FileMetadata[], boundary: DomainBoundary): Promise<ProcessedFile[]> {
    const results: ProcessedFile[] = [];
    
    // ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    const patternGroups = this.groupFilesByPattern(files);
    
    for (const [pattern, groupFiles] of patternGroups) {
      console.log(`ğŸ“ ãƒ‘ã‚¿ãƒ¼ãƒ³ "${pattern}" ã§ ${groupFiles.length}ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†`);
      
      const template = await this.getOrCreateTemplate(pattern, boundary);
      
      for (const file of groupFiles) {
        const generatedCode = this.applyTemplate(template, file);
        results.push({
          originalFile: file.path,
          generatedCode,
          method: 'template',
          confidence: 0.85,
          processingTime: 50 // ms - ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã¯é«˜é€Ÿ
        });
      }
    }
    
    return results;
  }

  /**
   * é™çš„è§£æã®ã¿ã®å‡¦ç†
   */
  private async processWithStaticAnalysis(files: FileMetadata[], boundary: DomainBoundary): Promise<ProcessedFile[]> {
    const results: ProcessedFile[] = [];
    
    for (const file of files) {
      const analysis = this.performStaticTransformation(file, boundary);
      results.push({
        originalFile: file.path,
        generatedCode: analysis.transformedCode,
        method: 'static',
        confidence: 0.6,
        processingTime: 10 // ms - é™çš„è§£æã¯è¶…é«˜é€Ÿ
      });
    }
    
    return results;
  }

  /**
   * é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã®å¢ƒç•Œãƒ•ã‚¡ã‚¤ãƒ«å–å¾—
   */
  private getBoundaryFiles(boundary: DomainBoundary): FileMetadata[] {
    if (!this.projectMetadata) return [];
    
    const boundaryFileSet = new Set(boundary.files);
    return this.projectMetadata.files.filter(file => 
      boundaryFileSet.has(file.path) || 
      boundaryFileSet.has(path.relative(this.projectRoot, file.path))
    );
  }

  /**
   * å…¨é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã®åé›†
   */
  private collectAllRelevantFiles(projectPath: string, boundaries: DomainBoundary[]): string[] {
    const allFiles = new Set<string>();
    
    for (const boundary of boundaries) {
      for (const file of boundary.files) {
        const fullPath = path.isAbsolute(file) ? file : path.join(projectPath, file);
        allFiles.add(fullPath);
      }
    }
    
    return Array.from(allFiles);
  }

  /**
   * ã‚¹ãƒãƒ¼ãƒˆãƒãƒƒãƒã®ä½œæˆï¼ˆé–¢é€£æ€§ã«åŸºã¥ãï¼‰
   */
  private createSmartBatches(files: FileMetadata[], maxBatchSize: number = 3): FileMetadata[][] {
    const batches: FileMetadata[][] = [];
    const processed = new Set<string>();
    
    for (const file of files) {
      if (processed.has(file.path)) continue;
      
      const batch = [file];
      processed.add(file.path);
      
      // é–¢é€£ãƒ•ã‚¡ã‚¤ãƒ«ã‚’åŒã˜ãƒãƒƒãƒã«è¿½åŠ 
      for (const other of files) {
        if (processed.has(other.path) || batch.length >= maxBatchSize) continue;
        
        if (this.areFilesRelated(file, other)) {
          batch.push(other);
          processed.add(other.path);
        }
      }
      
      batches.push(batch);
    }
    
    return batches;
  }

  /**
   * ãƒ•ã‚¡ã‚¤ãƒ«é–¢é€£æ€§ã®åˆ¤å®šï¼ˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼‰
   */
  private areFilesRelated(file1: FileMetadata, file2: FileMetadata): boolean {
    // ãƒ“ã‚¸ãƒã‚¹ã‚³ãƒ³ã‚»ãƒ—ãƒˆã®å…±é€šåº¦
    const conceptOverlap = this.calculateConceptOverlap(
      file1.businessContext.domainConcepts,
      file2.businessContext.domainConcepts
    );
    
    // æŠ€è¡“çš„é–¢é€£æ€§
    const technicalRelation = this.calculateTechnicalRelation(file1, file2);
    
    // ä¾å­˜é–¢ä¿‚
    const dependencyRelation = this.hasDependencyRelation(file1, file2);
    
    return conceptOverlap > 0.3 || technicalRelation > 0.5 || dependencyRelation;
  }

  /**
   * åŠ¹ç‡æ€§ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¨ˆç®—
   */
  private calculateEfficiencyMetrics(result: MetadataDrivenResult): void {
    const totalFiles = result.efficiency.totalFiles;
    const llmFiles = result.efficiency.llmProcessedFiles;
    const templateFiles = result.efficiency.templateGeneratedFiles;
    const staticFiles = result.efficiency.staticAnalyzedFiles;
    
    // ãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸›ç‡ã®æ¨å®š
    const estimatedFullLLMTokens = totalFiles * 2000; // å¹³å‡2000ãƒˆãƒ¼ã‚¯ãƒ³/ãƒ•ã‚¡ã‚¤ãƒ«
    const actualTokenUsage = (llmFiles * 2000) + (templateFiles * 200) + (staticFiles * 0);
    result.efficiency.tokenReduction = Math.round((1 - actualTokenUsage / estimatedFullLLMTokens) * 100);
    
    // å‡¦ç†æ™‚é–“çŸ­ç¸®ç‡ã®æ¨å®š
    const estimatedFullLLMTime = totalFiles * 10000; // 10ç§’/ãƒ•ã‚¡ã‚¤ãƒ«
    const actualTime = (llmFiles * 10000) + (templateFiles * 500) + (staticFiles * 100);
    result.efficiency.processingTimeReduction = Math.round((1 - actualTime / estimatedFullLLMTime) * 100);
  }

  // ä¸è¶³ãƒ¡ã‚½ãƒƒãƒ‰ã®å®Ÿè£…
  private optimizeBatchProcessing(files: FileMetadata[]): string[] {
    return [`Batched ${files.length} files for optimized processing`];
  }

  private async executeLLMBatch(batch: FileMetadata[], prompt: string, boundary: DomainBoundary): Promise<ProcessedFile[]> {
    return batch.map(file => ({
      originalFile: file.path,
      generatedCode: `// Generated for ${boundary.name}\n// Original: ${path.basename(file.path)}`,
      method: 'llm' as const,
      confidence: 0.9,
      processingTime: 8000
    }));
  }

  private identifyCommonPatterns(batch: FileMetadata[]): string[] {
    const allConcepts = batch.flatMap(f => f.businessContext.domainConcepts);
    const unique = [...new Set(allConcepts)];
    return unique.slice(0, 3);
  }

  private getRelevantCodeSnippet(file: FileMetadata): string {
    return `// Code snippet from ${path.basename(file.path)}\n// Functions: ${file.structure.functions.map(f => f.name).join(', ')}`;
  }

  private groupFilesByPattern(files: FileMetadata[]): Map<string, FileMetadata[]> {
    const groups = new Map<string, FileMetadata[]>();
    
    for (const file of files) {
      const pattern = file.llmHints.templateCompatible ? 'CRUD' : 'CUSTOM';
      if (!groups.has(pattern)) {
        groups.set(pattern, []);
      }
      groups.get(pattern)!.push(file);
    }
    
    return groups;
  }

  private async getOrCreateTemplate(pattern: string, boundary: DomainBoundary): Promise<string> {
    return `// Template for ${pattern} in ${boundary.name} boundary`;
  }

  private applyTemplate(template: string, file: FileMetadata): string {
    return `${template}\n// Applied to ${path.basename(file.path)}`;
  }

  private performStaticTransformation(file: FileMetadata, boundary: DomainBoundary): { transformedCode: string } {
    return {
      transformedCode: `// Static transformation for ${path.basename(file.path)} in ${boundary.name}`
    };
  }

  // ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆå®Ÿè£…çœç•¥ï¼‰
  private calculateConceptOverlap(concepts1: string[], concepts2: string[]): number {
    const set1 = new Set(concepts1);
    const set2 = new Set(concepts2);
    const intersection = new Set([...set1].filter(x => set2.has(x)));
    const union = new Set([...set1, ...set2]);
    return union.size > 0 ? intersection.size / union.size : 0;
  }

  private calculateTechnicalRelation(file1: FileMetadata, file2: FileMetadata): number {
    // åŒã˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã€é¡ä¼¼ã®æ§‹é€ ãƒ‘ã‚¿ãƒ¼ãƒ³ãªã©ã‚’è©•ä¾¡
    return 0.5; // ç°¡ç•¥åŒ–
  }

  private hasDependencyRelation(file1: FileMetadata, file2: FileMetadata): boolean {
    // import/exporté–¢ä¿‚ã‚’ãƒã‚§ãƒƒã‚¯
    return false; // ç°¡ç•¥åŒ–
  }
}

// å‹å®šç¾©
interface MetadataDrivenResult {
  boundaries: BoundaryResult[];
  efficiency: EfficiencyMetrics;
}

interface BoundaryResult {
  boundary: string;
  llmProcessed: ProcessedFile[];
  templateGenerated: ProcessedFile[];
  staticAnalyzed: ProcessedFile[];
  optimizations: string[];
}

interface ProcessedFile {
  originalFile: string;
  generatedCode: string;
  method: 'llm' | 'template' | 'static';
  confidence: number;
  processingTime: number;
}

interface OptimizedProcessingPlan {
  llm: FileMetadata[];
  template: FileMetadata[];
  static: FileMetadata[];
  optimizations: string[];
}

interface EfficiencyMetrics {
  totalFiles: number;
  llmProcessedFiles: number;
  templateGeneratedFiles: number;
  staticAnalyzedFiles: number;
  processingTimeReduction: number;
  tokenReduction: number;
}