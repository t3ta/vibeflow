#!/usr/bin/env node
/**
 * VibeFlow CLI entry point.
 * Generates plan and runs refactor tasks on target project.
 */

import { Command } from 'commander';
import chalk from 'chalk';
import * as path from 'path';
import * as fs from 'fs/promises';
import { BoundaryAgent } from './core/agents/boundary-agent.js';
import { EnhancedBoundaryAgent } from './core/agents/enhanced-boundary-agent.js';
import { ArchitectAgent } from './core/agents/architect-agent.js';
import { RefactorAgent } from './core/agents/refactor-agent.js';
import { TestSynthAgent } from './core/agents/test-synth-agent.js';
import { MigrationRunner } from './core/agents/migration-runner.js';
import { ReviewAgent } from './core/agents/review-agent.js';
import { VibeFlowPaths } from './core/utils/file-paths.js';
import { executeAutoRefactor } from './core/workflow/auto-refactor-workflow.js';
import { CostManager } from './core/utils/cost-manager.js';
import { HybridRefactorAgent } from './core/agents/hybrid-refactor-agent.js';
import { IncrementalMigrationRunner } from './core/agents/incremental-migration-runner.js';
import { EnhancedTestSynthAgent } from './core/agents/enhanced-test-synth-agent.js';
import { BusinessLogicMigrationAgent } from './core/agents/business-logic-migration-agent.js';
import { TestSynthesisAgent } from './core/agents/test-synthesis-agent.js';
import { handleResumeFlow } from './core/utils/checkpoint-manager.js';
import { MetadataDrivenRefactorAgent } from './core/agents/metadata-driven-refactor-agent.js';
import { MetricsCLI } from './core/utils/metrics-cli.js';

// -----------------------------------------------------------------------------
// Workflow execution functions
// -----------------------------------------------------------------------------
async function runAutomaticBoundaryDiscovery(projectRoot: string): Promise<void> {
  const absolutePath = path.resolve(projectRoot);
  
  // Verify project exists
  try {
    await fs.access(absolutePath);
  } catch {
    throw new Error(`Project directory not found: ${absolutePath}`);
  }

  console.log(chalk.blue(`ğŸ¤– AIè‡ªå‹•å¢ƒç•Œç™ºè¦‹: ${absolutePath}`));
  console.log(chalk.gray('è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ä¸è¦ - AIãŒå®Œå…¨è‡ªå‹•ã§ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å¢ƒç•Œã‚’ç™ºè¦‹ã—ã¾ã™'));
  
  try {
    // AIå®Œå…¨è‡ªå‹•å¢ƒç•Œç™ºè¦‹ï¼ˆè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãªã—ã§å®Ÿè¡Œï¼‰
    const enhancedBoundaryAgent = new EnhancedBoundaryAgent(absolutePath, undefined, undefined);
    const boundaryResult = await enhancedBoundaryAgent.analyzeBoundaries();
    
    console.log(chalk.green('âœ¨ AIè‡ªå‹•å¢ƒç•Œç™ºè¦‹å®Œäº†!'));
    console.log(chalk.cyan('\nğŸ“Š ç™ºè¦‹çµæœã‚µãƒãƒª:'));
    console.log(chalk.gray(`   ğŸ¯ ç™ºè¦‹ã•ã‚ŒãŸå¢ƒç•Œ: ${boundaryResult.autoDiscoveredBoundaries.length}å€‹`));
    console.log(chalk.gray(`   ğŸ“ˆ å…¨ä½“ä¿¡é ¼åº¦: ${boundaryResult.discoveryMetrics.confidence_metrics.overall_confidence.toFixed(1)}%`));
    console.log(chalk.gray(`   ğŸ—ï¸  æ§‹é€ ä¸€è²«æ€§: ${boundaryResult.discoveryMetrics.confidence_metrics.structural_coherence.toFixed(1)}%`));
    console.log(chalk.gray(`   ğŸ—„ï¸  DBæ•´åˆæ€§: ${boundaryResult.discoveryMetrics.confidence_metrics.database_alignment.toFixed(1)}%`));
    
    console.log(chalk.cyan('\nğŸ¯ ç™ºè¦‹ã•ã‚ŒãŸå¢ƒç•Œ:'));
    boundaryResult.autoDiscoveredBoundaries
      .slice(0, 10)
      .forEach((boundary, i) => {
        console.log(chalk.gray(`   ${i + 1}. ${boundary.name} (ä¿¡é ¼åº¦${(boundary.confidence * 100).toFixed(1)}%)`));
        console.log(chalk.gray(`      â””â”€ ${boundary.description}`));
        console.log(chalk.gray(`      â””â”€ ãƒ•ã‚¡ã‚¤ãƒ«æ•°: ${boundary.files.length}, ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: ${boundary.semantic_keywords.slice(0, 3).join(', ')}`));
      });
    
    if (boundaryResult.discoveryMetrics.recommendations.length > 0) {
      console.log(chalk.yellow('\nğŸ’¡ AIæ¨å¥¨äº‹é …:'));
      boundaryResult.discoveryMetrics.recommendations
        .slice(0, 5)
        .forEach((rec, i) => {
          console.log(chalk.gray(`   ${i + 1}. ${rec.reason}`));
          console.log(chalk.gray(`      â””â”€ ${rec.expected_benefit}`));
        });
    }
    
    const paths = new VibeFlowPaths(absolutePath);
    console.log(chalk.green('\nğŸ“„ Generated files:'));
    console.log(chalk.gray(`   - ${paths.getRelativePath(boundaryResult.outputPath)} (ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒãƒƒãƒ—)`));
    console.log(chalk.gray(`   - ${paths.getRelativePath(paths.autoBoundaryReportPath)} (è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ)`));
    
    console.log(chalk.cyan('\nâœ¨ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:'));
    console.log(chalk.gray('   1. ç”Ÿæˆã•ã‚ŒãŸãƒ‰ãƒ¡ã‚¤ãƒ³ãƒãƒƒãƒ—ã‚’ç¢ºèª'));
    console.log(chalk.gray('   2. å¿…è¦ã«å¿œã˜ã¦vibeflow.config.yamlã‚’ä½œæˆ'));
    console.log(chalk.gray('   3. vf plan ã§ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆã‚’å®Ÿè¡Œ'));
    console.log(chalk.gray('   4. vf refactor ã§å®Ÿéš›ã®ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã‚’å®Ÿè¡Œ'));
    
  } catch (error) {
    console.error(chalk.red('âŒ Error in automatic boundary discovery:'), error);
    throw error;
  }
}

async function planTasks(projectRoot: string): Promise<void> {
  const absolutePath = path.resolve(projectRoot);
  
  // Verify project exists
  try {
    await fs.access(absolutePath);
  } catch {
    throw new Error(`Project directory not found: ${absolutePath}`);
  }

  console.log(chalk.blue(`ğŸ“‚ Analyzing project: ${absolutePath}`));
  
  try {
    // 1. Enhanced Boundary Analysis (AI + Manual)
    const enhancedBoundaryAgent = new EnhancedBoundaryAgent(absolutePath);
    const boundaryResult = await enhancedBoundaryAgent.analyzeBoundaries();
    
    // 2. Architectural Design
    const architectAgent = new ArchitectAgent(absolutePath);
    const architectResult = await architectAgent.generateArchitecturalPlan(boundaryResult.outputPath);
    
    const planPaths = new VibeFlowPaths(absolutePath);
    console.log(chalk.green('âœ… Plan generation complete!'));
    console.log(chalk.gray('ğŸ“„ Generated files:'));
    console.log(chalk.gray(`   - ${planPaths.getRelativePath(boundaryResult.outputPath)}`));
    console.log(chalk.gray(`   - ${planPaths.getRelativePath(architectResult.outputPath)}`));
    
    // Display AI discovery results
    if (boundaryResult.autoDiscoveredBoundaries.length > 0) {
      console.log(chalk.cyan('\nğŸ¤– AIè‡ªå‹•å¢ƒç•Œç™ºè¦‹çµæœ:'));
      console.log(chalk.gray(`   ç™ºè¦‹ã•ã‚ŒãŸå¢ƒç•Œ: ${boundaryResult.autoDiscoveredBoundaries.length}å€‹`));
      console.log(chalk.gray(`   å…¨ä½“ä¿¡é ¼åº¦: ${boundaryResult.discoveryMetrics.confidence_metrics.overall_confidence.toFixed(1)}%`));
      
      if (boundaryResult.hybridRecommendations.length > 0) {
        console.log(chalk.yellow(`   æ¨å¥¨äº‹é …: ${boundaryResult.hybridRecommendations.length}å€‹`));
        boundaryResult.hybridRecommendations.slice(0, 3).forEach((rec, i) => {
          console.log(chalk.gray(`     ${i + 1}. ${rec.action}`));
        });
      }
    }
    
  } catch (error) {
    console.error(chalk.red('âŒ Error in plan generation:'), error);
    throw error;
  }
}

async function runRefactor(projectRoot: string, apply: boolean, resumeOptions?: any): Promise<void> {
  const absolutePath = path.resolve(projectRoot);
  const paths = new VibeFlowPaths(absolutePath);
  
  // Verify required files exist
  const planPath = paths.planPath;
  const domainMapPath = paths.domainMapPath;
  
  // Check for required files unless in test environment
  if (process.env.NODE_ENV !== 'test' && process.env.VITEST !== 'true') {
    try {
      await fs.access(planPath);
      await fs.access(domainMapPath);
    } catch {
      throw new Error(
        `Required files not found. Please run "vf plan" first to generate ${paths.getRelativePath(planPath)} and ${paths.getRelativePath(domainMapPath)}`
      );
    }
  } else {
    console.log(chalk.yellow('ğŸ”§ Test environment - skipping required file validation'));
  }

  console.log(chalk.blue(`ğŸ”§ Refactoring project: ${absolutePath}`));
  
  try {
    // 1. Business Logic Migration (AI-powered)
    console.log(chalk.blue('ğŸ§  Step 1/5: AI-powered business logic migration...'));
    const businessLogicAgent = new BusinessLogicMigrationAgent(absolutePath);
    const businessLogicResult = await businessLogicAgent.execute({
      projectPath: absolutePath,
      domainMapPath: domainMapPath,
      planPath: planPath,
      aiEnabled: true,
      language: 'go' as const, // TODO: Auto-detect language
      preserveMode: 'strict',
      generateTests: true,
      generateDocumentation: true
    });
    
    console.log(chalk.green(`âœ… æ¥­å‹™ãƒ­ã‚¸ãƒƒã‚¯ç§»è¡Œå®Œäº†: ${businessLogicResult.migratedBoundaries.length}å€‹ã®å¢ƒç•Œã‚’å‡¦ç†`));
    console.log(chalk.gray(`   AIå‡¦ç†: ${businessLogicResult.aiProcessedFiles}ãƒ•ã‚¡ã‚¤ãƒ«, é™çš„è§£æ: ${businessLogicResult.staticAnalysisFiles}ãƒ•ã‚¡ã‚¤ãƒ«`));
    
    // 2. Test Synthesis for files without tests
    console.log(chalk.blue('ğŸ§ª Step 2/5: AI-powered test synthesis...'));
    const testSynthesisAgent = new TestSynthesisAgent(absolutePath);
    const testSynthesisResult = await testSynthesisAgent.execute({
      projectPath: absolutePath,
      language: 'go' as const,
      outputPath: path.join(absolutePath, '__generated__/tests'),
      documentationPath: path.join(absolutePath, '__generated__/docs'),
      aiEnabled: true,
      generateDocumentation: true,
      localization: 'ja'
    });
    
    console.log(chalk.green(`âœ… ãƒ†ã‚¹ãƒˆç”Ÿæˆå®Œäº†: ${testSynthesisResult.generatedTests.length}å€‹ã®ãƒ†ã‚¹ãƒˆ, ${testSynthesisResult.generatedDocuments.length}å€‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ`));
    
    // 3. Generate refactoring patches
    console.log(chalk.blue('ğŸ—ï¸  Step 3/5: Generating refactoring patches...'));
    const refactorAgent = new RefactorAgent(absolutePath);
    const refactorResult = await refactorAgent.generateRefactorPlan(planPath);
    
    // 4. Synthesize and relocate tests
    console.log(chalk.blue('ğŸ”„ Step 4/5: Test relocation and synthesis...'));
    const testSynthAgent = new TestSynthAgent(absolutePath);
    const testSynthResult = await testSynthAgent.synthesizeTests(paths.patchesDir);
    
    // 5. Run migration (apply patches)
    console.log(chalk.blue('ğŸš€ Step 5/5: Applying patches and migration...'));
    const migrationRunner = new MigrationRunner(absolutePath, undefined, !apply);
    const migrationResult = await migrationRunner.executeMigration(paths.patchesDir, apply);
    
    // 6. Review changes
    const reviewAgent = new ReviewAgent(absolutePath);
    const reviewResult = await reviewAgent.reviewChanges(migrationResult.outputPath);
    
    console.log(chalk.green('âœ… AI-poweredå®Œå…¨ãªãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº†!'));
    console.log(chalk.gray('ğŸ“„ Generated files:'));
    console.log(chalk.gray(`   - ${paths.getRelativePath(refactorResult.outputPath)}/ (${refactorResult.plan.summary.total_patches} patches)`));
    console.log(chalk.gray(`   - ${paths.getRelativePath(testSynthResult.outputPath)} (${testSynthResult.generated_tests.length} tests)`));
    console.log(chalk.gray(`   - ${paths.getRelativePath(migrationResult.outputPath)} (migration results)`));
    console.log(chalk.gray(`   - ${paths.getRelativePath(reviewResult.outputPath)} (review report)`));
    console.log(chalk.gray(`   - __generated__/tests/ (${testSynthesisResult.generatedTests.length} AI-generated tests)`));
    console.log(chalk.gray(`   - __generated__/docs/ (${testSynthesisResult.generatedDocuments.length} user stories & specs)`));
    
    // Display key results
    console.log(chalk.cyan('\nğŸ“Š å®Ÿè¡Œçµæœã‚µãƒãƒª:'));
    console.log(chalk.gray(`   ğŸ§  æ¥­å‹™ãƒ­ã‚¸ãƒƒã‚¯ç§»è¡Œ: ${businessLogicResult.migratedBoundaries.length}å¢ƒç•Œ (AI: ${businessLogicResult.aiProcessedFiles}, é™çš„: ${businessLogicResult.staticAnalysisFiles})`));
    console.log(chalk.gray(`   ğŸ§ª AIç”Ÿæˆãƒ†ã‚¹ãƒˆ: ${testSynthesisResult.generatedTests.length}å€‹ (ã‚«ãƒãƒ¬ãƒƒã‚¸å‘ä¸Šæ¨å®š: ${testSynthesisResult.coverageImprovement?.improvement || 'N/A'}%)`));
    console.log(chalk.gray(`   ğŸ“š ç”Ÿæˆãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: ${testSynthesisResult.generatedDocuments.length}å€‹ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚¹ãƒˆãƒ¼ãƒªãƒ¼ãƒ»ä»•æ§˜æ›¸`));
    console.log(chalk.gray(`   ğŸ”„ ãƒ‘ãƒƒãƒé©ç”¨: ${migrationResult.applied_patches.length}æˆåŠŸ / ${migrationResult.failed_patches.length}å¤±æ•—`));
    console.log(chalk.gray(`   âœ… ãƒ“ãƒ«ãƒ‰: ${migrationResult.build_result.success ? 'âœ… æˆåŠŸ' : 'âŒ å¤±æ•—'}`));
    console.log(chalk.gray(`   ğŸ§ª ãƒ†ã‚¹ãƒˆ: ${migrationResult.test_result.success ? 'âœ… æˆåŠŸ' : 'âŒ å¤±æ•—'}`));
    console.log(chalk.gray(`   ğŸ“‹ ç·åˆè©•ä¾¡: ${reviewResult.overall_assessment.grade}ã‚°ãƒ¬ãƒ¼ãƒ‰`));
    console.log(chalk.gray(`   ğŸ¤– è‡ªå‹•ãƒãƒ¼ã‚¸: ${reviewResult.auto_merge_decision.should_auto_merge ? 'âœ… å¯èƒ½' : 'âŒ æ‰‹å‹•ãƒ¬ãƒ“ãƒ¥ãƒ¼å¿…è¦'}`));
    
    if (!apply) {
      console.log(chalk.yellow('\nâ„¹ï¸  ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ãƒ¢ãƒ¼ãƒ‰ - å®Ÿéš›ã®å¤‰æ›´ã¯è¡Œã‚ã‚Œã¦ã„ã¾ã›ã‚“'));
      console.log(chalk.yellow('   --applyãƒ•ãƒ©ã‚°ã§å®Ÿéš›ã®å¤‰æ›´ã‚’é©ç”¨ã§ãã¾ã™'));
    }
    
  } catch (error) {
    console.error(chalk.red('âŒ Error in refactor execution:'), error);
    throw error;
  }
}

async function runIncrementalRefactor(projectRoot: string, options: {
  apply: boolean;
  maxStageSize: number;
  resumeFromStage?: number;
  skipStages: number[];
}): Promise<void> {
  const absolutePath = path.resolve(projectRoot);
  const paths = new VibeFlowPaths(absolutePath);
  
  // Check that plan exists
  const planPath = paths.planPath;
  const domainMapPath = paths.domainMapPath;
  
  // Check for required files unless in test environment
  if (process.env.NODE_ENV !== 'test' && process.env.VITEST !== 'true') {
    try {
      await fs.access(planPath);
      await fs.access(domainMapPath);
    } catch {
      throw new Error(
        `Required files not found. Please run "vf plan" first to generate ${paths.getRelativePath(planPath)} and ${paths.getRelativePath(domainMapPath)}`
      );
    }
  } else {
    console.log(chalk.yellow('ğŸ”§ Test environment - skipping required file validation'));
  }

  console.log(chalk.blue(`ğŸ”„ ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°: ${absolutePath}`));
  console.log(chalk.gray(`âš™ï¸  è¨­å®š: æœ€å¤§ã‚¹ãƒ†ãƒ¼ã‚¸ã‚µã‚¤ã‚º=${options.maxStageSize}, ã‚¹ã‚­ãƒƒãƒ—=[${options.skipStages.join(', ')}]`));
  
  if (options.resumeFromStage) {
    console.log(chalk.cyan(`ğŸ”‚ ã‚¹ãƒ†ãƒ¼ã‚¸${options.resumeFromStage}ã‹ã‚‰å†é–‹ã—ã¾ã™`));
  }
  
  try {
    // 1. Enhanced test synthesis for better coverage
    console.log(chalk.blue('ğŸ§ª Step 1/3: Enhanced test synthesis...'));
    const enhancedTestSynth = new EnhancedTestSynthAgent();
    const testSynthResult = await enhancedTestSynth.execute({
      projectPath: absolutePath,
      currentCoverage: 18.6, // From real experiment data
      targetCoverage: 50,
      language: 'go',
      testTypes: ['unit', 'integration'],
      aiEnabled: true,
    });
    
    console.log(chalk.green(`âœ… ãƒ†ã‚¹ãƒˆç”Ÿæˆå®Œäº†: ${testSynthResult.generatedTests.length}å€‹ã®æ–°è¦ãƒ†ã‚¹ãƒˆ`));
    console.log(chalk.gray(`   æ¨å®šã‚«ãƒãƒ¬ãƒƒã‚¸å‘ä¸Š: ${testSynthResult.coverageImprovement.beforeCoverage}% â†’ ${testSynthResult.coverageImprovement.estimatedAfterCoverage}%`));
    
    // 2. Generate refactoring patches
    console.log(chalk.blue('ğŸ—ï¸  Step 2/3: Generating refactoring patches...'));
    const refactorAgent = new RefactorAgent(absolutePath);
    const refactorResult = await refactorAgent.generateRefactorPlan(planPath);
    
    // 3. Execute incremental migration
    console.log(chalk.blue('ğŸ”§ Step 3/3: Incremental patch application...'));
    const incrementalRunner = new IncrementalMigrationRunner();
    const migrationResult = await incrementalRunner.execute({
      projectPath: absolutePath,
      refactorPlanPath: path.join(paths.patchesDir, 'manifest.json'),
      config: {
        maxStageSize: options.maxStageSize,
        maxRetries: 2,
        buildTimeout: 120000,
        testTimeout: 300000,
        continueOnNonCriticalFailure: true,
        generateProgressReport: true,
        createStageBackups: options.apply,
      },
      resumeFromStage: options.resumeFromStage,
      skipStages: options.skipStages,
    });
    
    // 4. Generate review report
    const reviewAgent = new ReviewAgent(absolutePath);
    const reviewResult = await reviewAgent.reviewChanges(absolutePath);
    
    console.log(chalk.green('âœ… ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å®Œäº†!'));
    
    // Display incremental results
    console.log(chalk.cyan('\nğŸ“Š å®Ÿè¡Œçµæœã‚µãƒãƒª:'));
    console.log(chalk.gray(`   ç·ã‚¹ãƒ†ãƒ¼ã‚¸æ•°: ${migrationResult.summary.totalStages}`));
    console.log(chalk.gray(`   æˆåŠŸã‚¹ãƒ†ãƒ¼ã‚¸: ${migrationResult.summary.successfulStages} âœ…`));
    console.log(chalk.gray(`   å¤±æ•—ã‚¹ãƒ†ãƒ¼ã‚¸: ${migrationResult.summary.failedStages} âŒ`));
    console.log(chalk.gray(`   ã‚¹ã‚­ãƒƒãƒ—ã‚¹ãƒ†ãƒ¼ã‚¸: ${migrationResult.summary.skippedStages} â­ï¸`));
    console.log(chalk.gray(`   ãƒ‘ãƒƒãƒé©ç”¨: ${migrationResult.summary.appliedPatches}/${migrationResult.summary.totalPatches}`));
    console.log(chalk.gray(`   æœ€çµ‚ãƒ“ãƒ«ãƒ‰: ${migrationResult.summary.finalBuildSuccess ? 'âœ… æˆåŠŸ' : 'âŒ å¤±æ•—'}`));
    console.log(chalk.gray(`   æœ€çµ‚ãƒ†ã‚¹ãƒˆ: ${migrationResult.summary.finalTestSuccess ? 'âœ… æˆåŠŸ' : 'âŒ å¤±æ•—'}`));
    console.log(chalk.gray(`   å‡¦ç†æ™‚é–“: ${(migrationResult.summary.processingTime / 1000).toFixed(1)}ç§’`));
    
    // Display recommendations
    if (migrationResult.recommendations.length > 0) {
      console.log(chalk.yellow('\nğŸ’¡ æ¨å¥¨äº‹é …:'));
      migrationResult.recommendations.forEach(rec => {
        console.log(chalk.yellow(`   - ${rec}`));
      });
    }
    
    // Display stage details
    console.log(chalk.cyan('\nğŸ“‹ ã‚¹ãƒ†ãƒ¼ã‚¸è©³ç´°:'));
    migrationResult.stageResults.forEach(result => {
      const statusIcon = result.decision === 'continue' ? 'âœ…' : 
                        result.decision === 'skip' ? 'â­ï¸' : 'âŒ';
      console.log(chalk.gray(`   ${statusIcon} Stage ${result.stage.id}: ${result.stage.name} (${result.applied.length}/${result.stage.patches.length} patches)`));
    });
    
    if (!options.apply) {
      console.log(chalk.yellow('\nâ„¹ï¸  ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ãƒ¢ãƒ¼ãƒ‰ - å®Ÿéš›ã®å¤‰æ›´ã¯è¡Œã‚ã‚Œã¦ã„ã¾ã›ã‚“'));
      console.log(chalk.yellow('   --applyãƒ•ãƒ©ã‚°ã§å®Ÿéš›ã®å¤‰æ›´ã‚’é©ç”¨ã§ãã¾ã™'));
    }
    
    // Suggest resume command if there were failures
    const lastFailedStage = migrationResult.stageResults
      .filter(r => r.decision === 'abort' || r.decision === 'skip')
      .pop();
    
    if (lastFailedStage && options.apply) {
      console.log(chalk.cyan(`\nğŸ”‚ å¤±æ•—ã—ãŸã‚¹ãƒ†ãƒ¼ã‚¸ã‹ã‚‰å†é–‹ã™ã‚‹ã«ã¯:`));
      console.log(chalk.cyan(`   vf refactor --incremental --apply --resume-from-stage ${lastFailedStage.stage.id}`));
    }
    
  } catch (error) {
    console.error(chalk.red('âŒ Error in incremental refactor execution:'), error);
    throw error;
  }
}

// -----------------------------------------------------------------------------
// CLI definition
// -----------------------------------------------------------------------------
const program = new Command()
  .name('vf')
  .description('VibeFlow CLI - modular monolith refactoring assistant')
  .version('0.1.0');

program
  .command('plan')
  .argument('[path]', 'target project root', 'workspace')
  .description('Generate refactor plan')
  .action(async (path: string) => {
    console.log(chalk.cyan('â–¶ generating plan...'));
    await planTasks(path);
  });

program
  .command('discover')
  .argument('[path]', 'target project root', 'workspace')
  .description('AI-powered automatic boundary discovery (no config required)')
  .action(async (path: string) => {
    console.log(chalk.magenta('â–¶ AI automatic boundary discovery...'));
    await runAutomaticBoundaryDiscovery(path);
  });

program
  .command('refactor')
  .argument('[path]', 'target project root', 'workspace')
  .option('-a, --apply', 'apply patches automatically')
  .option('-i, --incremental', 'use incremental migration mode for safer execution')
  .option('--max-stage-size <number>', 'maximum patches per stage (default: 5)', '5')
  .option('--resume-from-stage <number>', 'resume from specific stage number')
  .option('--skip-stages <numbers>', 'comma-separated list of stages to skip')
  .option('--resume', 'resume from previous checkpoint')
  .option('--retry-failed', 'retry previously failed files during resume')
  .option('--clear-checkpoint', 'clear existing checkpoint and start fresh')
  .option('--from-step <step>', 'resume from specific step (boundary, migration, refactor, test, review)')
  .option('--only-files <files...>', 'process only specified files or patterns')
  .description('Execute refactor according to plan')
  .action(async (pathParam: string, opts: { 
    apply?: boolean; 
    incremental?: boolean;
    maxStageSize?: string;
    resumeFromStage?: string;
    skipStages?: string;
    resume?: boolean;
    retryFailed?: boolean;
    clearCheckpoint?: boolean;
    fromStep?: string;
    onlyFiles?: string[];
  }) => {
    console.log(chalk.green('â–¶ running refactor...'));
    
    // Handle resume flow first
    const absolutePath = path.resolve(pathParam);
    const { shouldResume, checkpoint, resumeOptions } = await handleResumeFlow(absolutePath, {
      resume: opts.resume,
      retryFailed: opts.retryFailed,
      fromStep: opts.fromStep,
      clearCheckpoint: opts.clearCheckpoint,
      onlyFiles: opts.onlyFiles
    });
    
    if (opts.clearCheckpoint) {
      return; // Exit after clearing checkpoint
    }
    
    if (opts.incremental) {
      console.log(chalk.cyan('ğŸ”„ ã‚¤ãƒ³ã‚¯ãƒªãƒ¡ãƒ³ã‚¿ãƒ«ãƒ¢ãƒ¼ãƒ‰ - æ®µéšçš„ã«å®‰å…¨ã«å®Ÿè¡Œã—ã¾ã™'));
      await runIncrementalRefactor(pathParam, {
        apply: opts.apply ?? false,
        maxStageSize: parseInt(opts.maxStageSize || '5'),
        resumeFromStage: opts.resumeFromStage ? parseInt(opts.resumeFromStage) : undefined,
        skipStages: opts.skipStages ? opts.skipStages.split(',').map(n => parseInt(n.trim())) : [],
      });
    } else {
      await runRefactor(pathParam, opts.apply ?? false, shouldResume ? resumeOptions : undefined);
    }
  });

// Add quality analysis command
program
  .command('analyze-quality')
  .argument('[path]', 'target project root', 'workspace')
  .option('-l, --log <path>', 'path to refactor log file')
  .description('Analyze refactoring quality and determine if rerun is needed')
  .action(async (targetPath: string, opts: { log?: string }) => {
    const { analyzeRefactorQuality } = await import('./core/utils/refactor-quality-analyzer.js');
    const absolutePath = path.isAbsolute(targetPath) ? targetPath : path.join(process.cwd(), targetPath);
    await analyzeRefactorQuality(absolutePath, opts.log);
  });

// Add refine command for selective re-processing
program
  .command('refine')
  .argument('[path]', 'target project root', 'workspace')
  .option('-l, --log <path>', 'path to refactor log file')
  .option('-f, --files <files...>', 'specific files to refine')
  .option('--force-ai', 'force AI processing even with rate limits')
  .description('Refine specific files that need quality improvement')
  .action(async (targetPath: string, opts: { log?: string; files?: string[]; forceAi?: boolean }) => {
    const { runRefine } = await import('./core/agents/refine-agent.js');
    const absolutePath = path.isAbsolute(targetPath) ? targetPath : path.join(process.cwd(), targetPath);
    await runRefine(absolutePath, {
      log: opts.log,
      files: opts.files,
      forceAI: opts.forceAi
    });
  });

program
  .command('full')
  .argument('[path]', 'target project root', 'workspace')
  .option('-a, --apply', 'apply patches automatically')
  .description('Run complete pipeline: plan + refactor')
  .action(async (path: string, opts: { apply?: boolean }) => {
    console.log(chalk.cyan('â–¶ running full pipeline...'));
    
    try {
      // 1. Generate plan
      console.log(chalk.blue('ğŸ” Step 1/2: Generating plan...'));
      await planTasks(path);
      
      // 2. Execute refactor
      console.log(chalk.blue('ğŸ”§ Step 2/2: Executing refactor...'));
      await runRefactor(path, opts.apply ?? false);
      
      console.log(chalk.green('ğŸ‰ Complete pipeline finished successfully!'));
      
    } catch (error) {
      console.error(chalk.red('âŒ Pipeline failed:'), error);
      process.exit(1);
    }
  });

program
  .command('auto')
  .argument('[path]', 'target project root', 'workspace')
  .option('-a, --apply', 'actually apply changes (not dry-run)')
  .option('-l, --language <lang>', 'target language', 'go')
  .option('-p, --pattern <pattern>', 'architecture pattern', 'clean-arch')
  .option('-t, --timeout <minutes>', 'timeout in minutes', '60')
  .description('ğŸ¤– Complete automatic refactoring with AI - The Revolutionary Command')
  .action(async (path: string, opts: { 
    apply?: boolean; 
    language?: string; 
    pattern?: string; 
    timeout?: string;
  }) => {
    console.log(chalk.green('ğŸ¤– Running in Hybrid Mode'));
    console.log(chalk.gray('   Claude Code SDK + Templates for optimal results'));
    console.log(chalk.gray('   Falls back to template mode if AI unavailable'));
    console.log('');
    console.log(chalk.blue(`ğŸ“ Target: ${path}`));
    console.log(chalk.blue(`ğŸ”¤ Language: ${opts.language}`));
    console.log(chalk.blue(`ğŸ—ï¸  Pattern: ${opts.pattern}`));
    console.log(chalk.blue(`âš™ï¸  Mode: ${opts.apply ? chalk.red('ğŸ”¥ APPLY CHANGES') : chalk.yellow('ğŸ” DRY RUN')}`));
    console.log('');
    
    const startTime = Date.now();
    
    try {
      // Timeout setting
      const timeoutMs = parseInt(opts.timeout || '60') * 60 * 1000;
      const timeoutPromise = new Promise((_, reject) => 
        setTimeout(() => reject(new Error('â° Timeout reached')), timeoutMs)
      );
      
      // Execute automatic refactoring workflow
      const refactorPromise = executeAutoRefactor(path, opts.apply);
      
      const result = await Promise.race([refactorPromise, timeoutPromise]) as any;
      
      const duration = ((Date.now() - startTime) / 1000 / 60).toFixed(1);
      
      console.log('');
      console.log(chalk.green('ğŸ‰ AI Automatic Refactoring Complete!'));
      console.log(chalk.cyan(`â±ï¸  Total Time: ${duration} minutes`));
      console.log('');
      console.log(chalk.cyan('ğŸ“Š Execution Summary:'));
      console.log(chalk.gray(`   ğŸ—ï¸  Created modules: ${result.boundaries?.length || 0}`));
      console.log(chalk.gray(`   ğŸ”„ Converted files: ${result.refactorResult?.applied_patches?.length || 0}`));
      console.log(chalk.gray(`   ğŸ§ª Generated tests: ${result.testResult?.generated_tests?.length || 0}`));
      console.log(chalk.gray(`   âœ… Compile: ${result.validation?.compile?.success ? 'Success' : 'Failed'}`));
      console.log(chalk.gray(`   ğŸ§ª Tests: ${result.validation?.tests?.success ? 'Success' : 'Failed'}`));
      console.log(chalk.gray(`   ğŸ“ˆ Performance: ${result.validation?.performance?.improvement || 'N/A'}`));
      console.log('');
      
      if (!opts.apply) {
        console.log(chalk.yellow('â„¹ï¸  This was a dry run. Use --apply flag to actually apply changes.'));
        console.log(chalk.yellow('   Example: vf auto . --apply'));
      } else {
        console.log(chalk.green('ğŸš€ Production ready! Your codebase has been transformed.'));
        console.log(chalk.green('   Welcome to the new era of AI-powered development.'));
      }
      
    } catch (error) {
      const duration = ((Date.now() - startTime) / 1000 / 60).toFixed(1);
      console.log('');
      console.error(chalk.red(`âŒ Refactoring failed (${duration} min elapsed):`), (error as any).message);
      console.log(chalk.red('ğŸ”„ Automatic rollback executed.'));
      console.log('');
      process.exit(1);
    }
  });

// -----------------------------------------------------------------------------
// Cost estimation command
// -----------------------------------------------------------------------------
program
  .command('business-logic')
  .argument('[path]', 'target project root', 'workspace')
  .option('-a, --apply', 'apply changes automatically')
  .option('-l, --language <lang>', 'target language (go, typescript, python)', 'go')
  .option('--ai-enabled', 'enable Claude Code AI processing (recommended)', true)
  .option('--preserve-mode <mode>', 'preservation mode (strict, adaptive, optimized)', 'strict')
  .option('--generate-tests', 'generate tests for extracted business logic', true)
  .option('--generate-docs', 'generate human-readable documentation', true)
  .description('ğŸ§  AI-powered business logic migration and test synthesis')
  .action(async (pathParam: string, opts: { 
    apply?: boolean; 
    language?: string;
    aiEnabled?: boolean;
    preserveMode?: string;
    generateTests?: boolean;
    generateDocs?: boolean;
  }) => {
    console.log(chalk.magenta('ğŸ§  AI-powered Business Logic Migration'));
    console.log(chalk.gray('   Extract, migrate, and document business logic with Claude Code'));
    console.log('');
    
    const absolutePath = path.resolve(pathParam);
    const paths = new VibeFlowPaths(absolutePath);
    
    try {
      console.log(chalk.blue('ğŸ” Step 1/2: Business logic migration...'));
      const businessLogicAgent = new BusinessLogicMigrationAgent(absolutePath);
      const businessLogicResult = await businessLogicAgent.execute({
        projectPath: absolutePath,
        domainMapPath: paths.domainMapPath,
        planPath: paths.planPath,
        aiEnabled: opts.aiEnabled ?? true,
        language: (opts.language as any) || 'go',
        preserveMode: opts.preserveMode as any || 'strict',
        generateTests: opts.generateTests ?? true,
        generateDocumentation: opts.generateDocs ?? true
      });
      
      console.log(chalk.blue('ğŸ§ª Step 2/2: Test synthesis and documentation...'));
      const testSynthesisAgent = new TestSynthesisAgent(absolutePath);
      const testSynthesisResult = await testSynthesisAgent.execute({
        projectPath: absolutePath,
        language: (opts.language as any) || 'go',
        outputPath: path.join(absolutePath, '__generated__/tests'),
        documentationPath: path.join(absolutePath, '__generated__/docs'),
        aiEnabled: opts.aiEnabled ?? true,
        generateDocumentation: opts.generateDocs ?? true,
        localization: 'ja'
      });
      
      console.log(chalk.green('âœ… Business Logic Migration Complete!'));
      console.log(chalk.cyan('\nğŸ“Š Results Summary:'));
      console.log(chalk.gray(`   ğŸ§  Migrated boundaries: ${businessLogicResult.migratedBoundaries.length}`));
      console.log(chalk.gray(`   ğŸ¤– AI processed files: ${businessLogicResult.aiProcessedFiles}`));
      console.log(chalk.gray(`   ğŸ“Š Static analysis files: ${businessLogicResult.staticAnalysisFiles}`));
      console.log(chalk.gray(`   ğŸ§ª Generated tests: ${testSynthesisResult.generatedTests.length}`));
      console.log(chalk.gray(`   ğŸ“š Generated docs: ${testSynthesisResult.generatedDocuments.length}`));
      console.log('');
      console.log(chalk.cyan('ğŸ“ Generated Files:'));
      console.log(chalk.gray('   - __generated__/tests/ (AI-generated test cases)'));
      console.log(chalk.gray('   - __generated__/docs/ (User stories and specifications)'));
      
      if (!opts.apply) {
        console.log(chalk.yellow('\nâ„¹ï¸  Analysis mode - no files were modified'));
        console.log(chalk.yellow('   Use --apply to generate actual test and documentation files'));
      }
      
    } catch (error) {
      console.error(chalk.red('âŒ Business logic migration failed:'), error);
      process.exit(1);
    }
  });

program
  .command('estimate <path>')
  .description('ğŸ’° Estimate AI transformation costs')
  .option('-d, --detailed', 'show detailed breakdown')
  .action(async (targetPath: string, opts: { detailed?: boolean }) => {
    console.log(chalk.blue('ğŸ’° Cost Estimation for AI Transformation'));
    console.log('');

    try {
      const absolutePath = path.resolve(targetPath);
      
      // Run boundary discovery
      const boundaryAgent = new EnhancedBoundaryAgent(absolutePath);
      const { domainMap } = await boundaryAgent.analyzeBoundaries();
      
      // Estimate with hybrid agent
      const hybridAgent = new HybridRefactorAgent(absolutePath);
      const estimate = await hybridAgent.estimateCost(domainMap.boundaries);
      
      // Check cost limits
      const costManager = new CostManager(absolutePath);
      await costManager.initialize();
      const limitCheck = await costManager.checkLimits(estimate.estimatedCost, 'refactor');
      
      console.log(chalk.yellow('ğŸ“Š Estimation Results:'));
      console.log(chalk.gray(`   Files to process: ${estimate.fileCount}`));
      console.log(chalk.gray(`   Estimated tokens: ${estimate.estimatedTokens.toLocaleString()}`));
      console.log(chalk.gray(`   Estimated cost: $${estimate.estimatedCost.toFixed(2)}`));
      console.log(chalk.gray(`   Estimated time: ${estimate.estimatedTime}`));
      console.log('');
      
      const usage = costManager.getUsageReport();
      console.log(chalk.cyan('ğŸ’³ Current Usage:'));
      console.log(chalk.gray(`   Today: $${usage.today.cost.toFixed(2)} (${usage.today.operations} operations)`));
      console.log(chalk.gray(`   This month: $${usage.thisMonth.cost.toFixed(2)} (${usage.thisMonth.operations} operations)`));
      console.log('');
      console.log(chalk.cyan('ğŸ”’ Cost Limits:'));
      console.log(chalk.gray(`   Per run: $${usage.limits.perRun.toFixed(2)}`));
      console.log(chalk.gray(`   Daily: $${usage.limits.daily.toFixed(2)}`));
      console.log(chalk.gray(`   Monthly: $${usage.limits.monthly.toFixed(2)}`));
      console.log('');
      
      if (!limitCheck.allowed) {
        console.log(chalk.red(`âŒ ${limitCheck.reason}`));
      } else {
        console.log(chalk.green('âœ… Within cost limits'));
      }
      
      console.log(chalk.yellow('â„¹ï¸  Using Claude Code SDK (OAuth-based)'));
      console.log(chalk.gray('   Template mode always available as fallback'));

      if (opts.detailed && domainMap.boundaries.length > 0) {
        console.log('');
        console.log(chalk.cyan('ğŸ“ Boundary Breakdown:'));
        for (const boundary of domainMap.boundaries) {
          console.log(chalk.gray(`   ${boundary.name}: ${boundary.files.length} files`));
        }
      }

    } catch (error) {
      console.error(chalk.red('âŒ Estimation failed:'), error);
      process.exit(1);
    }
  });

program
  .command('refactor-smart')
  .argument('[path]', 'target project root', 'workspace')
  .option('-a, --apply', 'apply patches automatically')
  .option('--cache-only', 'use only cached metadata (skip analysis)')
  .option('--clear-cache', 'clear metadata cache before processing')
  .option('--show-plan', 'show optimization plan without executing')
  .description('Execute metadata-driven smart refactoring with optimized token usage')
  .action(async (pathParam: string, opts: { 
    apply?: boolean;
    cacheOnly?: boolean;
    clearCache?: boolean;
    showPlan?: boolean;
  }) => {
    try {
      console.log(chalk.blue('ğŸš€ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿é§†å‹•ã‚¹ãƒãƒ¼ãƒˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°é–‹å§‹...'));
      
      const absolutePath = path.resolve(pathParam);
      const paths = new VibeFlowPaths(absolutePath);
      
      // Load domain map
      const domainMapPath = paths.domainMapPath;
      let domainMap;
      try {
        const domainMapContent = await fs.readFile(domainMapPath, 'utf8');
        domainMap = JSON.parse(domainMapContent);
      } catch {
        console.error(chalk.red('âŒ ãƒ‰ãƒ¡ã‚¤ãƒ³ãƒãƒƒãƒ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã¾ãš "vf plan" ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚'));
        process.exit(1);
      }

      // Create metadata-driven agent
      const metadataAgent = new MetadataDrivenRefactorAgent(absolutePath);
      
      // Clear cache if requested
      if (opts.clearCache) {
        console.log(chalk.yellow('ğŸ—‘ï¸ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ä¸­...'));
        // Implementation would clear the cache directory
      }
      
      // Execute metadata-driven refactoring
      const result = await metadataAgent.executeMetadataDrivenRefactoring(
        absolutePath, 
        domainMap.boundaries
      );
      
      // Show optimization plan
      if (opts.showPlan) {
        console.log(chalk.cyan('\nğŸ“‹ æœ€é©åŒ–ãƒ—ãƒ©ãƒ³:'));
        for (const boundary of result.boundaries) {
          console.log(chalk.yellow(`\nğŸ“ ${boundary.boundary}:`));
          console.log(chalk.gray(`   ğŸ¤– LLMå‡¦ç†: ${boundary.llmProcessed.length}ãƒ•ã‚¡ã‚¤ãƒ«`));
          console.log(chalk.gray(`   ğŸ“ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ: ${boundary.templateGenerated.length}ãƒ•ã‚¡ã‚¤ãƒ«`));
          console.log(chalk.gray(`   âš¡ é™çš„è§£æ: ${boundary.staticAnalyzed.length}ãƒ•ã‚¡ã‚¤ãƒ«`));
          
          if (boundary.optimizations.length > 0) {
            console.log(chalk.green('   ğŸ’¡ æœ€é©åŒ–:'));
            boundary.optimizations.forEach(opt => 
              console.log(chalk.green(`      â€¢ ${opt}`))
            );
          }
        }
        
        console.log(chalk.cyan('\nğŸ“Š åŠ¹ç‡æ€§ãƒ¡ãƒˆãƒªã‚¯ã‚¹:'));
        console.log(chalk.green(`ğŸ’° ãƒˆãƒ¼ã‚¯ãƒ³å‰Šæ¸›: ${result.efficiency.tokenReduction}%`));
        console.log(chalk.green(`â±ï¸ å‡¦ç†æ™‚é–“çŸ­ç¸®: ${result.efficiency.processingTimeReduction}%`));
        console.log(chalk.gray(`ğŸ“ˆ ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: ${result.efficiency.totalFiles}`));
        console.log(chalk.gray(`ğŸ¤– LLMå‡¦ç†: ${result.efficiency.llmProcessedFiles}ãƒ•ã‚¡ã‚¤ãƒ«`));
        console.log(chalk.gray(`ğŸ“ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ: ${result.efficiency.templateGeneratedFiles}ãƒ•ã‚¡ã‚¤ãƒ«`));
        console.log(chalk.gray(`âš¡ é™çš„è§£æ: ${result.efficiency.staticAnalyzedFiles}ãƒ•ã‚¡ã‚¤ãƒ«`));
        
        if (!opts.apply) {
          console.log(chalk.yellow('\nğŸ’¡ å®Ÿéš›ã«ãƒ‘ãƒƒãƒã‚’é©ç”¨ã™ã‚‹ã«ã¯ --apply ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„'));
          return;
        }
      }
      
      console.log(chalk.green('âœ¨ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿é§†å‹•ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å®Œäº†!'));
      
    } catch (error) {
      console.error(chalk.red('âŒ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿é§†å‹•ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å¤±æ•—:'), error);
      process.exit(1);
    }
  });

// -----------------------------------------------------------------------------
// Metrics Commands
// -----------------------------------------------------------------------------

program
  .command('metrics')
  .argument('[path]', 'target project root', '.')
  .option('--run-id <id>', 'show details for specific run ID')
  .option('--agent <name>', 'filter by agent name')
  .option('--days <number>', 'number of days to include', '30')
  .option('--limit <number>', 'maximum number of runs to show', '20')
  .option('--export <format>', 'export data (csv|json)')
  .option('--output <file>', 'output file path for export')
  .option('--cleanup <days>', 'cleanup old data (retention days)')
  .description('Show performance metrics and statistics')
  .action(async (pathParam: string, opts: {
    runId?: string;
    agent?: string;
    days?: string;
    limit?: string;
    export?: 'csv' | 'json';
    output?: string;
    cleanup?: string;
  }) => {
    try {
      const absolutePath = path.resolve(pathParam);
      const metricsCLI = new MetricsCLI(absolutePath);
      
      // Cleanup operation
      if (opts.cleanup) {
        const retentionDays = parseInt(opts.cleanup);
        await metricsCLI.cleanup(retentionDays);
        metricsCLI.close();
        return;
      }
      
      // Export operation
      if (opts.export) {
        const days = parseInt(opts.days || '30');
        await metricsCLI.exportData(opts.export, opts.output, opts.agent, days);
        metricsCLI.close();
        return;
      }
      
      // Show specific run details
      if (opts.runId) {
        const runId = parseInt(opts.runId);
        await metricsCLI.showRunDetails(runId);
        metricsCLI.close();
        return;
      }
      
      // Show run history
      const limit = parseInt(opts.limit || '20');
      await metricsCLI.showRunHistory(opts.agent, limit);
      
      // Show statistics
      const days = parseInt(opts.days || '30');
      await metricsCLI.showAgentStats(opts.agent, days);
      
      metricsCLI.close();
      
    } catch (error) {
      console.error(chalk.red('âŒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—å¤±æ•—:'), error);
      process.exit(1);
    }
  });

// -----------------------------------------------------------------------------
// Entry
// -----------------------------------------------------------------------------
program.parseAsync(process.argv).catch((err) => {
  console.error(chalk.red('âœ–'), err);
  process.exit(1);
});
